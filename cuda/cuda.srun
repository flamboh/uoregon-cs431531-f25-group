#!/bin/bash
#SBATCH --account=cis431_531
#SBATCH --job-name=tucker_gpu   ### Job Name
#SBATCH --output=output/tucker_%A.out  ### File in which to store job output
#SBATCH --error=output/tucker_%A.err   ### File in which to store job error messages
#SBATCH --partition=gpu       ### Quality of Service (like a queue in PBS)
#SBATCH --time=1-00:00:00     ### Wall clock time limit in Days-HH:MM:SS
#SBATCH --nodes=1             ### Node count required for the job
#SBATCH --ntasks-per-node=1   ### Nuber of tasks to be launched per Node
#SBATCH --gres=gpu:1          ### General REServation of gpu:number of gpus
#SBATCH --cpus-per-task=28    ### Number of threads per task (OMP threads)

module load cuda/12.4

export OMP_PROC_BIND=true
export OMP_NUM_THREADS=$SLURM_ARRAY_TASK_ID



./cuda_tests 5000 0 6 7 10 10 10 10 10 10 10 3
